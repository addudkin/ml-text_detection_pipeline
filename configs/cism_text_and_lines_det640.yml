description:
  repo: TD
  project_name: esse
  experiment_name: new_annotation_baseline

mlflow: null # если не требуется, то просто убираем этот блок
#  # exp_name - в таком видео в mlflow будет отображаться эксперимент
#  exp_name: ${description.repo}/${description.project_name}/${description.experiment_name}
#  url: https://ml.dbrain.io/ # hostname на котором поднят mlflow сервис
#  username: ds # логин
#  password: EitahsaeghoXooz1Hiev # пароль
#  run_id: null #6ab6434ddf2d4db494490053535611ea # ID запуска в эксперименте, нужен если хотите сохранить веса во время
  # конвертации в конкретный эксперимент, если null будет выбран последний по дате создания
tensorboard:  null # если не требуется, то просто убираем этот блок
#  # Папка куда буду складываться логи тензорборда
#  log_dir: logs/${description.repo}/${description.project_name}/${description.experiment_name}

logging:
  image:
    height: 224
    width: 224
  log_images_every_n_epoch: 5

data:
  datasets:
    cism:
      images_folder: /home/addudkin/ml_text_detection/data/new_markup/images
      annotation_folder: /home/addudkin/ml_text_detection/data/new_markup
      p: 1.0
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]

data_preprocess:
  data_folder: /home/addudkin/ml_text_detection/data/prepare_new_markup

train:
  epoch: 1000
  image_size: [640, 480]
  batch_size: 8
  workers: 12
  pin_memory: True
  gpu_index: 0

val:
  batch_size: 8

checkpoint:
  # Количество отслеживаемых лучших checkpoints для дальнейшего усреднения
  average_top_k: 5

# Имя класса используемого датасета из datasets/__init__.py
dataset_name: TextDetLines

model:
  class_model: DB
  backbone:
    type: resnet34
    args:
      in_channels: 3
      pretrained: true
  neck:
    type: FPN
    args:
      inner_channels: 256
  head:
    type: DBHeadLines
    args:
      out_channels: 2
      k: 50
  weights: ""

training_type: &training_type multilabel

loss_function:
  classic_DB:
    type: DBLoss
    params:
      alpha: 5
      beta: 10
      ohem_ratio: 3
  lines_segm:
    type: MultiLoss
    params:
      loss_1:
        name: FocalLoss
        weight: 1
        param:
          reduction: mean
          mode: *training_type
      loss_2:
        name: TverskyLoss
        weight: 1
        param:
          alpha: 0.5
          beta: 0.5
          mode: *training_type

optimizer:
  type: AdamW
  params:
    lr: 1.0e-3
    betas: [ 0.9, 0.999 ]
    weight_decay: 0.0001

scheduler:
  # Имя класса
  type: CosineAnnealingLR
  # Передаваемые параметры
  params:
    T_max: ${train.epoch}
    eta_min: 0

border_creator:
  params:
    shrink_ratio: 0.4
    thresh_min: 0.3
    thresh_max: 0.7

mask_shrinker:
  params:
    shrink_ratio: 0.4
    min_text_size: 8
    shrink_type: 'pyclipper'

post_processor:
  params:
    unclip_ratio: 2.25
    binarization_threshold: 0.3
    confidence_threshold: 0.7
    min_area: 10.

train_transforms:
  - ColorJitter:
      p: 0.3
      brightness: 0.12
      saturation: 0.5
  - HorizontalFlip:
      p: 0.3
  - OneOf:
      p: 1.0
      args:
        - ElasticTransform:
            p: 0.3
            border_mode: 0
        - ShiftScaleRotate:
            shift_limit: 0.1
            rotate_limit: 3
            shift_limit_y: 0.07
            shift_limit_x: 0.07
            border_mode: 0
            p: 0.3

train_pre_transforms:
    OneOf:
      p: 0.5
      args:
        - DirtyDrumTransform:
            p: 1.0
        - LightingGradientTransform:
            p: 1.0
#        - BadPhotoCopyTransform:
#            p: 1.0
#            noise_iteration: [ 1, 1 ]
#            noise_value: [ 32, 64 ]

val_pre_transforms: null

val_transforms: null

test_transforms: null
