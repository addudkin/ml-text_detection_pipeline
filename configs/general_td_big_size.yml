description:
  repo: TD
  project_name: "Experiments: FullText TD"
  experiment_name: baseline
  dataset_id: c2ae1558fdbe435abf3f468b22908277
  gt_dataset_id: 51f0e2ca239846cd9421fb5a5c8b49ee

init_cleaml: False
mlflow: null # если не требуется, то просто убираем этот блок
#  # exp_name - в таком видео в mlflow будет отображаться эксперимент
#  exp_name: ${description.repo}/${description.project_name}/${description.experiment_name}
#  url: https://ml.dbrain.io/ # hostname на котором поднят mlflow сервис
#  username: ds # логин
#  password: EitahsaeghoXooz1Hiev # пароль
#  run_id: null #6ab6434ddf2d4db494490053535611ea # ID запуска в эксперименте, нужен если хотите сохранить веса во время
  # конвертации в конкретный эксперимент, если null будет выбран последний по дате создания
tensorboard:
  log_dir: logs/${description.repo}/${description.project_name}/${description.experiment_name}

data:
  datasets:
    pervichka:
      images_folder: /home/addudkin/ml-text_detection_pipeline/data
      annotation_folder: /home/addudkin/ml-text_detection_pipeline/data
      p: 1.0
  sample_name:
    train: train_annotation.json
    val: val_annotation.json
  mean: [0.83908421, 0.88127789, 0.90946536]
  std: [0.12534873, 0.12586502, 0.1288737 ]


data_preprocess:
  data_folder: /home/addudkin/ml-text_detection_pipeline/data_prepared_mask/
  augmentation:
    OneOf:
      p: 0.5
      args:
        - DirtyDrumTransform:
            p: 1.0
        - LightingGradientTransform:
            p: 1.0

train:
  epoch: 100
  image_size: [2048, 2048]
  batch_size: 32
  workers: 8
  pin_memory: True
  gpu_index: 0

val:
  batch_size: 1
  image_size: [2048, 2048]

gt:
  batch_size: 1
  image_size: [ 2048, 2048 ]

resizer:
  input_size: [2048, 2048]
  aspect_ratio: true
  padding_type: both
  padding_value: 0
  interpolation_method: INTER_NEAREST

checkpoint:
  # Количество отслеживаемых лучших checkpoints для дальнейшего усреднения
  average_top_k: 5

# Имя класса используемого датасета из datasets/__init__.py
dataset_name:
  train: pervichka_dataset.TextDetPervichka
  val: pervichka_dataset.TextDetPervichka
  gt: pervichka_dataset_gt.TextDetPervichkaGT

model:
  class_model: DB
  backbone:
    type: resnet34
    args:
      in_channels: 3
      pretrained: true
  neck:
    type: FPN
    args:
      inner_channels: 256
  head:
    type: DBHead
    args:
      out_channels: 2
      k: 50
  weights: ""

training_type: &training_type multilabel

loss_function:
  type: DBLoss
  params:
    alpha: 5
    beta: 10
    ohem_ratio: 3

optimizer:
  type: AdamW
  params:
    lr: 1.0e-3
    betas: [ 0.9, 0.999 ]
    weight_decay: 0.0001

scheduler:
  # Имя класса
  type: CosineAnnealingLR
  # Передаваемые параметры
  params:
    T_max: ${train.epoch}
    eta_min: 0

border_creator:
  params:
    shrink_ratio: 0.5
    thresh_min: 0.3
    thresh_max: 0.7

mask_shrinker:
  params:
    shrink_ratio: 0.5
    min_text_size: 8
    shrink_type: 'pyclipper'

post_processor:
  params:
    shrink_ratio: 1.5
    intersection_threshold: 0.5
    confidence_threshold: 0.0
    min_area: 10.
    binarization_threshold: 0.3

train_transforms:
  - RandomCrop:
        p: 1
        width: 640
        height: 640
  - ColorJitter:
      p: 0.3
      brightness: 0.12
      saturation: 0.5
  - HorizontalFlip:
      p: 0.3
  - OneOf:
      p: 1.0
      args:
        - ElasticTransform:
            p: 0.3
            border_mode: 0
        - ShiftScaleRotate:
            shift_limit: 0.1
            rotate_limit: 3
            shift_limit_y: 0.1
            shift_limit_x: 0.1
            border_mode: 0
            p: 0.3

train_pre_transforms: null

val_pre_transforms: null

val_transforms: null

test_transforms: null
