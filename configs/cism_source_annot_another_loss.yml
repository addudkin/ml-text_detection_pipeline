description:
  repo: TD
  project_name: global
  experiment_name: source_annot_5_10_loss

mlflow: # если не требуется, то просто убираем этот блок
  # exp_name - в таком видео в mlflow будет отображаться эксперимент
  exp_name: ${description.repo}/${description.project_name}/${description.experiment_name}
  url: https://ml.dbrain.io/ # hostname на котором поднят mlflow сервис
  username: ds # логин
  password: EitahsaeghoXooz1Hiev # пароль
  run_id: null #6ab6434ddf2d4db494490053535611ea # ID запуска в эксперименте, нужен если хотите сохранить веса во время
  # конвертации в конкретный эксперимент, если null будет выбран последний по дате создания
tensorboard: # если не требуется, то просто убираем этот блок
  # Папка куда буду складываться логи тензорборда
  log_dir: logs/${description.repo}/${description.project_name}/${description.experiment_name}

logging:
  image:
    height: 224
    width: 224
  log_images_every_n_epoch: 5

data:
  datasets:
    cism:
      images_folder: /home/addudkin/cism/data/images
      annotation_folder: /home/addudkin/cism/data
      p: 1.0
  # bank_doc:
  #   adapter: banc_doc
  #   args:
  #     ann_dir: /mnt/ssd1/DOC_BANC/text/DocBank_500K_txt
  #     img_dir: /mnt/ssd1/DOC_BANC/full_data/DocBank_500K_ori_img
  #     in_memory: false
  #   p: 0.25
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]

train:
  epoch: 1000
  crop_size: [640, 640]
  batch_size: 8
  workers: 12
  pin_memory: True
  gpu_index: 1

val:
  batch_size: 1

checkpoint:
  # Количество отслеживаемых лучших checkpoints для дальнейшего усреднения
  average_top_k: 5

# Имя класса используемого датасета из datasets/__init__.py
dataset_name: MultiTDDataset

model:
  class_model: DB
  backbone:
    type: resnet34
    args:
      in_channels: 3
      pretrained: true
  neck:
    type: FPN
    args:
      inner_channels: 256
  head:
    type: DBHead
    args:
      out_channels: 2
      k: 50
  weights: ""

loss_function:
  type: DBLoss
  params:
    alpha: 5
    beta: 10
    ohem_ratio: 3

optimizer:
  type: AdamW
  params:
    lr: 1.0e-3
    betas: [ 0.9, 0.999 ]
    weight_decay: 0.0001

scheduler:
  # Имя класса
  type: CosineAnnealingLR
  # Передаваемые параметры
  params:
    T_max: ${train.epoch}
    eta_min: 0


border_creator:
  params:
    shrink_ratio: 0.4
    thresh_min: 0.3
    thresh_max: 0.7

mask_shrinker:
  params:
    shrink_ratio: 0.4
    min_text_size: 8
    shrink_type: 'pyclipper'

post_processor:
  params:
    unclip_ratio: 2.25
    binarization_threshold: 0.3
    confidence_threshold: 0.7
    min_area: 10.

train_transforms:
  - ColorJitter:
      p: 0.5
      brightness: 0.12
      saturation: 0.5
  - HorizontalFlip:
      p: 0.5

val_transforms: null

test_transforms: null
